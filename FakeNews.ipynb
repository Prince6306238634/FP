{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWGsdzj7R5cyQMuhYpqc3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prince6306238634/FP/blob/master/FakeNews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K75Fq-kSTDla",
        "outputId": "46efd84c-850b-4e11-f426-cf4de7dc51e9"
      },
      "source": [
        "# Import Data\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l44PWKF1YmwH"
      },
      "source": [
        "**Load the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSPySQ8LUzCj"
      },
      "source": [
        "# Load the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the train and test files\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/fakenewskdd2020.zip (Unzipped Files)/train.csv\", sep='\\t', encoding='utf-8')\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/fakenewskdd2020.zip (Unzipped Files)/test.csv\", sep='\\t', encoding='utf-8')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eBTpfujWVJEb",
        "outputId": "b70baf1d-94c2-418e-fe0b-71d7551a2086"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Get the latest from TODAY Sign up for our news...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2d  Conan On The Funeral Trump Will Be Invited...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It’s safe to say that Instagram Stories has fa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Much like a certain Amazon goddess with a lass...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>At a time when the perfect outfit is just one ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Get the latest from TODAY Sign up for our news...     1\n",
              "1  2d  Conan On The Funeral Trump Will Be Invited...     1\n",
              "2  It’s safe to say that Instagram Stories has fa...     0\n",
              "3  Much like a certain Amazon goddess with a lass...     0\n",
              "4  At a time when the perfect outfit is just one ...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI2rvPwQYvrm"
      },
      "source": [
        "**Bag of Words pipeline** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFmeMpcYVJVm",
        "outputId": "dca83e17-9a80-4754-a738-a5bf422ffe0c"
      },
      "source": [
        "import nltk #Import NLTK ---> Natural Language Toolkit\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "d4NfaeBSVJsP",
        "outputId": "180f2644-5b69-4046-9474-230554ec9e6f"
      },
      "source": [
        "train['text'].loc[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Get the latest from TODAY Sign up for our newsletter  No one ever truly gets over losing a loved one, and Blake Shelton is no exception. He was just 14 when his older brother Richie died on Nov. 13, 1990. And, as Shelton noted in a tweet Monday, \"It changed my life forever.\"  Richie was 24 when he died in a car accident in the Sheltons\\' home state of Oklahoma. Two years ago, Shelton sent out a message for the 25th anniversary of his loss:  Richie, who was Blake\\'s half-brother (they shared a mother), was a passenger in a car that collided with a school bus in Ada, south of Oklahoma City.  Richie, driver Redena McManus and a 3-year-old boy, Christopher McManus, all died during or shortly after the collision, while the bus driver and passengers were uninjured, according to police reports.  The accident has clearly remained with Blake, who told 60 Minutes in 2014, \"I remember picking up the phone to call him a week after he was dead, to tell him something. I was picking up the phone to call him, to tell him something I just saw on TV or, and it was like constantly a shock to me that he was dead.\"  Blake Shelton playing at TODAY\\'s Halloween Extravaganza in New York City on Oct. 31. Getty Images  In 2011, Blake and his then-wife Miranda Lambert wrote a single called \"Over You,\" which was inspired by Richie.  Still, the two brothers had bonded despite the age difference; both shared a love of country music. \"His bedroom was right across the hallway from mine when I was little,\" Blake said in that interview. \"And he was listening to Hank Williams, Jr. or Waylon, Lynyrd Skynyrd or Bob Seeger. I just, whatever was popular really, Richie loved all music.  \"And I would be sitting there going, \\'Man, that guy\\'s my hero. That\\'s the coolest guy. He’s my big brother.\\'\"  Follow Randee Dawn on Twitter.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "83hcl05LVZ5X",
        "outputId": "2ccb4519-f557-47e3-d401-c76930ec3ba2"
      },
      "source": [
        "train.text.loc[ : 5].values.tolist()[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Get the latest from TODAY Sign up for our newsletter  No one ever truly gets over losing a loved one, and Blake Shelton is no exception. He was just 14 when his older brother Richie died on Nov. 13, 1990. And, as Shelton noted in a tweet Monday, \"It changed my life forever.\"  Richie was 24 when he died in a car accident in the Sheltons\\' home state of Oklahoma. Two years ago, Shelton sent out a message for the 25th anniversary of his loss:  Richie, who was Blake\\'s half-brother (they shared a mother), was a passenger in a car that collided with a school bus in Ada, south of Oklahoma City.  Richie, driver Redena McManus and a 3-year-old boy, Christopher McManus, all died during or shortly after the collision, while the bus driver and passengers were uninjured, according to police reports.  The accident has clearly remained with Blake, who told 60 Minutes in 2014, \"I remember picking up the phone to call him a week after he was dead, to tell him something. I was picking up the phone to call him, to tell him something I just saw on TV or, and it was like constantly a shock to me that he was dead.\"  Blake Shelton playing at TODAY\\'s Halloween Extravaganza in New York City on Oct. 31. Getty Images  In 2011, Blake and his then-wife Miranda Lambert wrote a single called \"Over You,\" which was inspired by Richie.  Still, the two brothers had bonded despite the age difference; both shared a love of country music. \"His bedroom was right across the hallway from mine when I was little,\" Blake said in that interview. \"And he was listening to Hank Williams, Jr. or Waylon, Lynyrd Skynyrd or Bob Seeger. I just, whatever was popular really, Richie loved all music.  \"And I would be sitting there going, \\'Man, that guy\\'s my hero. That\\'s the coolest guy. He’s my big brother.\\'\"  Follow Randee Dawn on Twitter.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwKZlCnYVaLh"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# create a function to tokenize the data\n",
        "def preprocess_data(data):\n",
        "  \n",
        "  # 1. Tokenization\n",
        "  tk = RegexpTokenizer('\\s+', gaps = True)\n",
        "  text_data = [] # List for storing the tokenized data\n",
        "  for values in data.text:\n",
        "    tokenized_data = tk.tokenize(values) # Tokenize the news\n",
        "    text_data.append(tokenized_data) # append the tokenized data\n",
        "\n",
        "  # 2. Stopword Removal\n",
        "\n",
        "  # Extract the stopwords\n",
        "  sw = stopwords.words('english')\n",
        "  clean_data = [] # List for storing the clean text\n",
        "  # Remove the stopwords using stopwords\n",
        "  for data in text_data:\n",
        "    clean_text = [words.lower() for words in data if words.lower() not in sw]\n",
        "    clean_data.append(clean_text) # Appned the clean_text in the clean_data list\n",
        "  \n",
        "  # 3. Stemming\n",
        "\n",
        "  # Create a stemmer object\n",
        "  ps = PorterStemmer()\n",
        "  stemmed_data = [] # List for storing the stemmed data\n",
        "  for data in clean_data:\n",
        "    stemmed_text = [ps.stem(words) for words in data] # Stem the words\n",
        "    stemmed_data.append(stemmed_text) # Append the stemmed text\n",
        "  \n",
        "\n",
        "  # 4. tfidf vectorizer --> Term Frequency Inverse Document Frequency\n",
        "\n",
        "  '''TF-IDF stands for Term Frequency Inverse Document Frequency of records. \n",
        "     It can be defined as the calculation of how relevant a word in a series or corpus is to a text. \n",
        "     The meaning increases proportionally to the number of times in the text a word appears but is compensated \n",
        "     by the word frequency in the corpus (data-set).'''\n",
        "\n",
        "  '''Term Frequency: In document d, the frequency represents the number of instances of a given word t. \n",
        "     Therefore, we can see that it becomes more relevant when a word appears in the text, which is rational. \n",
        "     Since the ordering of terms is not significant, we can use a vector to describe the text in the bag of term models. \n",
        "     For each specific term in the paper, there is an entry with the value being the term frequency.'''\n",
        "\n",
        "     # tf(t,d) = count of t in d / number of words in d\n",
        "\n",
        "  '''Document Frequency: This tests the meaning of the text, which is very similar to TF, in the whole corpus collection. \n",
        "     The only difference is that in document d, TF is the frequency counter for a term t, while df is the number of occurrences \n",
        "     in the document set N of the term t. In other words, the number of papers in which the word is present is DF.'''\n",
        "\n",
        "     # df(t) = occurrence of t in documents\n",
        "\n",
        "  '''Inverse Document Frequency: Mainly, it tests how relevant the word is. \n",
        "     The key aim of the search is to locate the appropriate records that fit the demand. \n",
        "     Since tf considers all terms equally significant, it is therefore not only possible to use the term frequencies \n",
        "     to measure the weight of the term in the paper. First, find the document frequency of a term t by counting the \n",
        "     number of documents containing the term.'''\n",
        "\n",
        "  ''' df(t) = N(t)\n",
        "      where\n",
        "      df(t) = Document frequency of a term t\n",
        "      N(t) = Number of documents containing the term t'''\n",
        "\n",
        "      # Take the log, idf(t) = log(N/ df(t))\n",
        "      # tf-idf(t, d) = tf(t, d) * idf(t)\n",
        "  \n",
        "  # Flatten the stemmed data\n",
        "\n",
        "  updated_data = []\n",
        "  for data in stemmed_data:\n",
        "    updated_data.append(\" \".join(data))\n",
        "\n",
        "  # TFID Vector object\n",
        "  tfidf = TfidfVectorizer()\n",
        "  tfidf_matrix = tfidf.fit_transform(updated_data)\n",
        "\n",
        "  return tfidf_matrix"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVQgaUgbVaYh"
      },
      "source": [
        "# Call the above function on the merged data\n",
        "train_len = train.shape[0]\n",
        "merged_data = pd.concat((train.drop('label', axis=1), test.drop('id', axis=1)), axis=0).reset_index().drop('index', axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbzCh1ztV53g"
      },
      "source": [
        "# preprocess the merged data\n",
        "preprocessed_data = preprocess_data(merged_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1T3INzAV5bi"
      },
      "source": [
        "train_data = preprocessed_data[ : train_len]\n",
        "test_data = preprocessed_data[train_len : ]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DiVReSwY9v4"
      },
      "source": [
        "**Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcm4rHh9WfQG"
      },
      "source": [
        "# Model selection\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, train.label, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piLavK9SWop7"
      },
      "source": [
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# model\n",
        "def compute_metrics(data, y_true, model_obj, model):\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = model_obj.predict(data)\n",
        "\n",
        "  # Compute accuracy\n",
        "  acc = accuracy_score(y_true = y_true, y_pred = y_pred)\n",
        "\n",
        "  # Make DataFrame\n",
        "  metrics = pd.DataFrame(data = np.array([acc]), index=[model], columns=['Accuracy Score'])\n",
        "  return metrics"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITq-gw5nWoX6",
        "outputId": "b58afea5-e330-4019-e9d9-0af5389d880f"
      },
      "source": [
        "# 1. LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# Model object\n",
        "lr_reg = LogisticRegressionCV(Cs=20, cv=3, random_state=42)\n",
        "\n",
        "# fit the model\n",
        "lr_reg.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=20, class_weight=None, cv=3, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=42, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVIfHAOTWey5"
      },
      "source": [
        "# Compute the Logistic Regression Metrics\n",
        "lr_metrics =  compute_metrics(X_test, y_test, lr_reg, 'LogisticRegression')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TS8dTpGW-wl"
      },
      "source": [
        "lr_metrics_train =  compute_metrics(X_train, y_train, lr_reg, 'LogisticRegression')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "BDOHU0P-W-g4",
        "outputId": "ed915486-db6f-4403-d8dd-aa4d4c746461"
      },
      "source": [
        "lr_metrics"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.778557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Accuracy Score\n",
              "LogisticRegression        0.778557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7L2ZZ53XKfD",
        "outputId": "e7d6608d-0a61-4044-8587-6b327cbdb5a2"
      },
      "source": [
        "#2. Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Model Object\n",
        "mnb = MultinomialNB(alpha=0.0)\n",
        "\n",
        "# Fit the object\n",
        "mnb.fit(X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "s2loXF3RXKsr",
        "outputId": "588dbc20-5076-438c-c9c5-1ae123b858e1"
      },
      "source": [
        "# Compute metrics\n",
        "mnb_metrics = compute_metrics(X_test, y_test, mnb, 'Naive Bayes')\n",
        "mnb_metrics"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.719439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Accuracy Score\n",
              "Naive Bayes        0.719439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4GPZ-QgXKzZ",
        "outputId": "ac818c9c-ab6c-4b4d-d79f-724464693087"
      },
      "source": [
        "# 3. DecisionTree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Model Object\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the object\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPz3Kmp1XYvU"
      },
      "source": [
        "dt_metrics = compute_metrics(X_test, y_test, dt_clf, \"DecisionTree\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "KleGSsT-XZFY",
        "outputId": "48985fa6-0174-4130-ad49-936d99595b89"
      },
      "source": [
        "dt_metrics"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTree</th>\n",
              "      <td>0.691383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Accuracy Score\n",
              "DecisionTree        0.691383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuQQxp5SXg6b",
        "outputId": "9f0fc1da-9995-4445-f5cd-f9aa2f79f3fb"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# XGB model\n",
        "xgb_model = XGBClassifier(n_estimators=200)\n",
        "\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8AOhDlrXlfM"
      },
      "source": [
        "xgb_metrics = compute_metrics(X_test, y_test, xgb_model, 'XGBClassifier')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr6XBUSOXloG"
      },
      "source": [
        "# Concatenate all the metrics\n",
        "model_metrics = pd.concat((lr_metrics, mnb_metrics, dt_metrics, xgb_metrics), axis=0).sort_values(by='Accuracy Score', ascending=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "6hEdDrEcXhHz",
        "outputId": "34656123-f441-49d2-9a5f-213deca3bbed"
      },
      "source": [
        "model_metrics"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.778557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.763527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTree</th>\n",
              "      <td>0.691383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Accuracy Score\n",
              "LogisticRegression        0.778557\n",
              "XGBClassifier             0.763527\n",
              "Naive Bayes               0.719439\n",
              "DecisionTree              0.691383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcJt2XfTZV67"
      },
      "source": [
        "**Making Predictions\n",
        "XGB Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVN4L0vVX4NO"
      },
      "source": [
        "# Make predictions --> XGBoost\n",
        "predictions = xgb_model.predict(test_data)\n",
        "# Submissions\n",
        "test_ID = test.id\n",
        "submissions = pd.DataFrame({'id' : test_ID, 'label' : predictions})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Dk48srC2X4ei",
        "outputId": "cc090b4a-122d-4b1e-8824-eee0ede5b68c"
      },
      "source": [
        "submissions.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id label\n",
              "0   2     0\n",
              "1   3     0\n",
              "2   4     1\n",
              "3   5     1\n",
              "4   6     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7W-ot7nX-Wl"
      },
      "source": [
        "submissions.to_csv(\"/content/predictions_4.csv\", index=False) # Convert the submissions to .csv"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY_16G3RZjwD"
      },
      "source": [
        "**Logistic Regression Predicitons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pcoBR-XX-JT"
      },
      "source": [
        "# make predictions--> Logistic Regression\n",
        "predictions2 = lr_reg.predict(test_data)\n",
        "# Submissions\n",
        "test_ID = test.id\n",
        "submissions2 = pd.DataFrame({'id' : test_ID, 'label' : predictions2})\n",
        "submissions2.to_csv(\"/content/predictions_5.csv\", index=False) # Convert the submissions to .csv"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}